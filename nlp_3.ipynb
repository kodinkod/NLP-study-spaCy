{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Работа с объектами-контейнерами и настройка spaCy\n",
    "под свои нужды\n",
    "========================\n",
    "05.10.2022"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Основные объекты, из которых состоит API spaCy, можно разделить на две категории: контейнеры (например, объекты Token и Doc) и компоненты конвейеров обработки (например, средства частеречной разметки и распознавания именованных сущностей). В этой главе продолжим изучение объектов-контейнеров: благодаря им и их методам можно получать доступ к лингвистическим меткам, которые библиотека spaCy присваивает всем токенам в тексте."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy as sp\n",
    "nlp = sp.load('ru_core_news_lg')\n",
    "input_1 = 'Здравствуйте. У меня болит горло..'\n",
    "input_2 = 'Привет, как дела?'\n",
    "input_3 = 'Где кошка'\n",
    "input_4 = 'Хочу купить булочку'\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![avatar](./doc.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Здравствуйте, ., У, меня, болит, горло, ..]\n",
      "[('Здравствуйте', 'ROOT', 'Здравствуйте'), ('Здравствуйте', 'punct', '.'), ('меня', 'case', 'У'), ('болит', 'obl', 'меня'), ('болит', 'ROOT', 'болит'), ('болит', 'nsubj', 'горло'), ('болит', 'punct', '..')]\n"
     ]
    }
   ],
   "source": [
    "from traceback import print_tb\n",
    "\n",
    "\n",
    "doc = nlp(input_1)\n",
    "\n",
    "doc_list = [doc[i] for i in range(len(doc))]   # по индексам\n",
    "print(doc_list)\n",
    "\n",
    "# можно обращаться к токенам\n",
    "\n",
    "print([(token.head.text, token.dep_, token.text) for token in doc])\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Пусть нам нужно найти левосторонний дочерний элемент токена в дереве синтаксических зависимостей предложения. Данная операция\n",
    "позволяет найти прилагательные (при их наличии) для заданного\n",
    "существительного. Этоможет понадобиться, если нужно узнать, какие\n",
    "прилагательные могут модифицировать заданное существительное.\n",
    "\n",
    "Можно также использовать атрибут Token.rights для получения правосторонних синтаксических дочерних элементов"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "болит\n",
      "[меня]\n"
     ]
    }
   ],
   "source": [
    "print(doc[4]) # слово\n",
    "print([w for w in doc[4].lefts]) # левостороннее дочернее"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Контейнер doc.sents\n",
    "doc.sents объекта Doc текст можно разделить на\n",
    "отдельные предложения"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Здравствуйте. У меня болит горло..\n",
      "[Здравствуйте, .]\n",
      "[У, меня, болит, горло, ..]\n"
     ]
    }
   ],
   "source": [
    "print(input_1)\n",
    "doc = nlp(input_1)\n",
    "\n",
    "for sent in doc.sents:\n",
    "    print([sent[i] for i in range(len(sent))])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "В то же время можно ссылаться на токены в состоящем из множества\n",
    "предложений тексте с помощью глобальных индексов уровня документа, как показано вот здесь:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Здравствуйте, ., У, меня, болит, горло, ..]"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[doc[i] for i in range(len(doc))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The second sentence begins with a pronoun.\n"
     ]
    }
   ],
   "source": [
    "doc = nlp(u'Здравствуйте Денис. Я могу предложить вам чай')\n",
    "\n",
    "\n",
    "for i,sent in enumerate(doc.sents):\n",
    "    if i==1 and sent[0].pos_== 'PRON':\n",
    "        print('The second sentence begins with a pronoun.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Предлодений с глагоом на конце: 2\n"
     ]
    }
   ],
   "source": [
    "# сколько предложений в текстве оканчивается глаголом?\n",
    "doc = nlp(u'Здравствуйте Денис.я хочу пить. Ты не хочешь. Ну и бог с тобой')\n",
    "\n",
    "counter = 0\n",
    "for sent in doc.sents:\n",
    "    if sent[len(sent)-2].pos_ == 'VERB':\n",
    "        counter+=1\n",
    "\n",
    "print('Предлодений с глаглом на конце:', counter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.0 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "6ce3869865918335a5f7f8bf564fd081cbfe04ed0827b527a250169e23ceeace"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
