{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 6. Поиск паттернов и обход деревьев зависимостей\n",
    "\n",
    "стр 116\n",
    "В этом ноутбуке есть информация по генерации текста (ответ на ворпос)\n",
    "Поиск паттернов.Комбинирование паттернов."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "В этой главе рассматриваются еще два подхода: использование паттернов (закономерностей) последовательностей слов для классификации и генерации текста, а также выделение из высказывания необходимых элементов информации путем обхода его дерева синтаксических зависимостей. Вы познакомитесь с утилитой Matcher библиотеки spaCy, предназначенной для поиска закономерностей. А также узнаете, в каких случаях для определения нужного подхода к обработке все равно приходится учитывать контекст."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Бвают совершенно различные предложения, но с одинаковыми паттернами (частями речи и зависимости между нимим)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy as sp\n",
    "nlp = sp.load('ru_core_news_lg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "doc1 = nlp(\"Я хочу на море\")\n",
    "doc2 = nlp(\"Мы летим в горы\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Я Мы nsubj nsubj\n",
      "хочу летим ROOT ROOT\n",
      "на в case case\n",
      "море горы obl obl\n"
     ]
    }
   ],
   "source": [
    "for i in range(len(doc1)):\n",
    "    print(doc1[i].text, doc2[i].text, doc1[i].dep_,doc2[i].dep_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Видно, что предложения совсем рахные, но паттерн у них одинкаовый: nsubj+ROOT+case+obl\n",
    "\n",
    "подробней об dep_ можно прочитать в start.ipynb // если коротко, то это метка синтакчической зависимости. Например, ROOT -означает, что это слово-смысловой глагол"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "поиск паттернов лучше. Потому что могут быть различные предложения по содержанию и смыслу, но одинаковые по построению"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Я nsubj\n",
      "хочу ROOT\n",
      "на case\n",
      "море obl\n",
      ". punct\n",
      "----------\n",
      "Мы nsubj\n",
      "летим ROOT\n",
      "в case\n",
      "горы obl\n",
      ". punct\n",
      "----------\n"
     ]
    }
   ],
   "source": [
    "# ПОПРОБУЙТЕ САМИ стр 118\n",
    "doc = nlp(\"Я хочу на море.Мы летим в горы.\")\n",
    "for item in doc.sents:\n",
    "    sentence = list(item)\n",
    "    for word in sentence:\n",
    "        print(word.text,word.dep_)\n",
    "    print(5*\"--\")\n",
    "\n",
    "# эффективней создавать один контейнер doc и приминять один раз nlp. Чем создавать два контейнера и проходить по ним. \n",
    "# Используй doc.sents "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Проверка высказывания на соответствие паттерну"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "На практике же обычно нет смысла сравнивать предложения друг с другом для выяснения, объединяет ли их один паттерн. Вместо этого стоит проверить полученное предложение на соответствие нужному нам паттерну."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------\n",
      "TEXT Я nsubj\n",
      "HEAD хочу nsubj\n",
      "<children\n",
      "/children>\n",
      "----------\n",
      "----------\n",
      "TEXT хочу ROOT\n",
      "HEAD хочу ROOT\n",
      "<children\n",
      "Я nsubj\n",
      "море obl\n",
      ". punct\n",
      "/children>\n",
      "----------\n",
      "----------\n",
      "TEXT на case\n",
      "HEAD море case\n",
      "<children\n",
      "/children>\n",
      "----------\n",
      "----------\n",
      "TEXT море obl\n",
      "HEAD хочу obl\n",
      "<children\n",
      "на case\n",
      "/children>\n",
      "----------\n",
      "----------\n",
      "TEXT . punct\n",
      "HEAD хочу punct\n",
      "<children\n",
      "/children>\n",
      "----------\n"
     ]
    }
   ],
   "source": [
    "# попробуем увидеть, как паттерн можно отследить \n",
    "# nsubj+ROOT+case+obl\n",
    "doc = nlp(\"Я хочу на море.\")\n",
    "\n",
    "for item in doc:\n",
    "    print(5*'--')\n",
    "    print('TEXT', item.text, item.dep_)\n",
    "    print('HEAD', item.head, item.dep_)\n",
    "    print(\"<children\")\n",
    "    for g in item.children:\n",
    "        print(g, g.dep_)\n",
    "    print('/children>')\n",
    "    print(5*'--')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dep_pattern(doc):\n",
    "    # если паттерн есть в предложении, то вернем true \n",
    "    for i in range(len(doc)-1):\n",
    "        if doc[i].dep_ == \"nsubj\":\n",
    "            #print(doc[i])\n",
    "            if doc[i].head.dep_ == \"ROOT\":\n",
    "            #    print(doc[i].head)\n",
    "                for child in doc[i].head.children:\n",
    "                    if child.dep_ ==\"obl\":\n",
    "                        return True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Я хочу на море\n",
      "found\n",
      "Мы летим в горы\n",
      "found\n",
      "Я купил машину\n",
      "dint found\n",
      "Мы летим в горы, а потом на море\n",
      "found\n"
     ]
    }
   ],
   "source": [
    "doc1 = nlp(\"Я хочу на море\")\n",
    "doc2 = nlp(\"Мы летим в горы\")\n",
    "doc3 = nlp(\"Я купил машину\")\n",
    "doc4 = nlp(\"Мы летим в горы, а потом на море\")\n",
    "\n",
    "testing = [doc1, doc2, doc3, doc4]\n",
    "\n",
    "\n",
    "for test in testing:\n",
    "    print(test.text)\n",
    "    if dep_pattern(test):\n",
    "        print(\"found\")\n",
    "    else:\n",
    "        print(\"dint found\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Использование утилиты Matcher библиотеки spaCy для поиска паттернов последовательностей слов"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![alt text](matcher.jpeg \"matcher\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "from spacy.matcher import Matcher"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SPAN: Я хочу на море\n",
      "Позиция в доке:  0 - 4\n"
     ]
    }
   ],
   "source": [
    "# DEP обращаемся по токену \n",
    "# nsubj+ROOT+case+obl\n",
    "\n",
    "matcher = Matcher(nlp.vocab)\n",
    "pattern = [{\"DEP\":\"nsubj\"},{\"DEP\":\"ROOT\"},{\"DEP\":\"case\"},{\"DEP\":\"obl\"}]\n",
    "matcher.add(\"NsubjRootcaseobl\", [pattern])\n",
    "\n",
    "doc = nlp(\"Я хочу на море. а он не хочет.\")\n",
    "\n",
    "match = matcher(doc)\n",
    "for match_id, start, end in match:\n",
    "    span = doc[start:end]\n",
    "    print(\"SPAN:\", span.text)\n",
    "    print('Позиция в доке: ',start,'-',end)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Матчер позволяет искать паттерны только, когда слова идут друг за другом. Если паттерн у нас такой: nsubj+ROOT+..<какой то текст>..+case+obl ; то матчер у нас не сможет работать. Далее посмотрим, как ещё можно искать паттерны в тексте."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Применение нескольких паттернов"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Одно высказывание можно сопоставить с несколькими паттернами, дабы убедиться, что оно удовлетворяет всем нужным условиям. Например, с двумя паттернами: с реализующим последовательность меток зависимости (как обсуждалось в подразделе «Проверка высказывания на соответствие паттерну» на с. 119) и с проверяющим на соответствие последовательности тегов частей речи. Это может пригодиться, скажем, если будет нужно убедиться, что в роли прямого дополнения в высказывании выступает личное местоимение. В таком случае можно начать поиск соответствующего этому местоимению существительного, упомянутого где-то в другом месте текста."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Напоминим - \n",
    "dep - это то, чем является слово в предложении по отношению к другим словам.\n",
    "\n",
    "pos - это часть речи. (PRON, VERB)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Я nsubj PRON\n",
      "хочу ROOT VERB\n",
      "на case ADP\n",
      "море obl NOUN\n",
      ". punct PUNCT\n",
      "----------\n",
      "Мы nsubj PRON\n",
      "летим ROOT VERB\n",
      "в case ADP\n",
      "горы obl NOUN\n",
      ". punct PUNCT\n",
      "----------\n"
     ]
    }
   ],
   "source": [
    "#увидим, что dep паттерн может совпасть, а pos паттерн совсем другой. Тогда нам нужна дополнительная функция \n",
    "#которая бы отбирала нужные части речи.\n",
    "\n",
    "doc = nlp(\"Я хочу на море.Мы летим в горы.\")\n",
    "for item in doc.sents:\n",
    "    sentence = list(item)\n",
    "    for word in sentence:\n",
    "        print(word.text,word.dep_, word.tag_)\n",
    "    print(5*\"--\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found\n"
     ]
    }
   ],
   "source": [
    "\n",
    "doc = nlp(\"Мы хотим на марс.\")\n",
    "\n",
    "# ИЩЕМ: nsubj+ROOT+case+obl\n",
    "#       PRON +VERB+ --+---\n",
    "\n",
    "# уже было\n",
    "def dep_pattern(doc):\n",
    "    # если паттерн есть в предложении, то вернем true \n",
    "    for i in range(len(doc)-1):\n",
    "        if doc[i].dep_ == \"nsubj\":\n",
    "            #print(doc[i])\n",
    "            if doc[i].head.dep_ == \"ROOT\":\n",
    "            #    print(doc[i].head)\n",
    "                for child in doc[i].head.children:\n",
    "                    if child.dep_ ==\"obl\":\n",
    "                        return True\n",
    "\n",
    "#дополняем \\\\ Можно точечно указать части речи, которые нас интересуют  \n",
    "def pos_pattern(doc):\n",
    "    for token in doc:\n",
    "        if token.dep_ == 'nsubj' and token.tag_ != 'PRON':\n",
    "            return False\n",
    "        if token.dep_ == 'ROOT' and token.tag_ != 'VERB':\n",
    "            return False\n",
    "    return True\n",
    "    \n",
    "# тестируем\n",
    "if dep_pattern(doc) and pos_pattern(doc):\n",
    "    print('Found')\n",
    "else:\n",
    "    print('Not found')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Создание паттернов на основе пользовательских признаков"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "При создании паттерна последовательности слов может возникнуть необходимость расширить функциональность лингвистических признаков, предоставляемых spaCy, подогнав их под свои задачи. Например, может понадобиться, чтобы предыдущий сценарий распознавал паттерн, в котором учитывается число местоимений (единственное или множественное). Это полезно в том случае, если нужно найти существительное, к которому относится местоимение."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Допустим нужно изучить существительное. Тогда нам нужно бы найти местоимение во множественном числе и найти относящееся к нему существительное."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "следующем сценарии описывается функция pron_pattern, которая находит все прямые дополнения в передаваемом ей предложении, определяет, является ли прямое дополнение личным местоимением, а затем выясняет, в каком оно числе: единственном или множественном. Далее функция применяется к примеру предложения после проверки его на соответствие двум паттернам, описанным в подразделах «Проверка высказывания на соответствие паттерну» на с. 119 и «Применение нескольких паттернов» на с. 122."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------------------------------\n",
      "Мы летим в горы с кошками\n",
      "Found: the pronoun in position of direct object is plural\n",
      "------------------------------------------------------------\n",
      "Я хочу марс.\n",
      "Not found\n",
      "------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "# исспользуем наши dep_pattern и pos_pattern\n",
    "\n",
    "def pron_pattern(doc):\n",
    "    plural = ['Мы','нам','они','им']\n",
    "    for token in doc:\n",
    "        if token.dep_ == 'nsubj' and token.tag_ == 'PRON':   # обнаруживаем местоимение в паттерне играющее роль nsubj\n",
    "            if token.text in plural:                        # если это местоимение в множественном числе \n",
    "                return 'plural'\n",
    "            else:\n",
    "                return 'singular'\n",
    "    return 'not found'\n",
    "\n",
    "\n",
    "\n",
    "print(30*\"--\")\n",
    "doc = nlp(u'Мы летим в горы с кошками')\n",
    "print(doc.text)\n",
    "if dep_pattern(doc) and pos_pattern(doc):\n",
    "    print('Found:', 'the pronoun in position of direct object is',\n",
    "    pron_pattern(doc))\n",
    "else:\n",
    "    print('Not found')\n",
    "\n",
    "print(30*\"--\")\n",
    "doc = nlp(u'Я хочу марс.')\n",
    "print(doc.text)\n",
    "if dep_pattern(doc) and pos_pattern(doc):\n",
    "    print('Found:', 'the pronoun in position of direct object is',\n",
    "    pron_pattern(doc))\n",
    "else:\n",
    "    print('Not found')\n",
    "\n",
    "print(30*\"--\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Выбор применяемых паттернов"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Столь слабое сцепление между паттернами позволяет использовать их совместно или по отдельности. Например, функцию dep_pattern, проверяющую предложение на соответствие паттерну «подлежащее + вспомогательный глагол + глагол + ... + прямое дополнение...», можно использовать вместе с функцией для паттерна «существительное + вспомогательный модальный глагол + глагол в неопределенной форме + ... + существительное...», дабы убедиться, что и подлежащее, и прямое дополнение в предложении — существительные. Этим двум паттернам будет удовлетворять следующий пример предложения\n",
    "\n",
    "Короче: паттерны можно и нужно комбинировать, чтобы писать меньше кода."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Применение паттернов последовательностей слов в чат-ботах для генерации высказываний"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "С помощью паттернов последовательностей слов можно реагировать на высказывания пользователя и другим образом — например, генерируя подходящие утвердительные высказывания."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Для подобной генерации текста можно воспользоваться паттернами, реализованными в предыдущих разделах. Перечень шагов подобной генерации выглядит примерно так.\n",
    "\n",
    "модифицируем действия. Сдеалем не так, как в книге, чтобы подходило для русского языка\n",
    "\n",
    "1. Проверить вводимые в диалоговом режиме данные с помощью описанных выше функций dep_pattern и pos_pattern и найти высказывание, которое удовлетворяет паттернам \n",
    "3. Найти обозначаемое этим местоимением существительное путем поиска существительного, которое управляет наше case местоимение\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "марс 12 16 LOC\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<span class=\"tex2jax_ignore\"><svg xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\" xml:lang=\"ru\" id=\"628fe12e525c40b78efe9ac24ddbbacb-0\" class=\"displacy\" width=\"750\" height=\"312.0\" direction=\"ltr\" style=\"max-width: none; height: 312.0px; color: #000000; background: #ffffff; font-family: Arial; direction: ltr\">\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"222.0\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"50\">Мы</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"50\">PRON</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"222.0\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"225\">хотим</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"225\">VERB</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"222.0\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"400\">на</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"400\">ADP</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"222.0\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"575\">марс</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"575\">NOUN</tspan>\n",
       "</text>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-628fe12e525c40b78efe9ac24ddbbacb-0-0\" stroke-width=\"2px\" d=\"M70,177.0 C70,89.5 220.0,89.5 220.0,177.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-628fe12e525c40b78efe9ac24ddbbacb-0-0\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">nsubj</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M70,179.0 L62,167.0 78,167.0\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-628fe12e525c40b78efe9ac24ddbbacb-0-1\" stroke-width=\"2px\" d=\"M420,177.0 C420,89.5 570.0,89.5 570.0,177.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-628fe12e525c40b78efe9ac24ddbbacb-0-1\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">case</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M420,179.0 L412,167.0 428,167.0\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-628fe12e525c40b78efe9ac24ddbbacb-0-2\" stroke-width=\"2px\" d=\"M245,177.0 C245,2.0 575.0,2.0 575.0,177.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-628fe12e525c40b78efe9ac24ddbbacb-0-2\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">obl</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M575.0,179.0 L583.0,167.0 567.0,167.0\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "</svg></span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from spacy import displacy # вот так могу, вот так вау\n",
    "doc = nlp(\"Мы хотим на марс\")\n",
    "for ent in doc.ents:\n",
    "    print(ent.text,ent.start_char, ent.end_char, ent.label_)  \n",
    "displacy.render(doc, style = 'dep')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4. Заменить в найденном при выполнении шага 1 предложении местоимение, играющее роль прямого дополнения, существительным, найденным на шаге 3.\n",
    "5. Добавить в конец сгенерированного высказывания слово too."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "#У нас есть такой поиск паттерна:\n",
    "# ИЩЕМ, nsubj+ROOT+case+obl  <- dep_pattern()\n",
    "#   C   PRON +VERB+ --+---   <- pos_pattern()\n",
    "# Число местоимения (множ. единственное.) <- pron_pattern()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Попробуем научится генерировать такие ответы.\n",
    "\n",
    "# Мы хотим на марс -> Я тоже хочу на марс\n",
    "# Я хочу на море -> Я тоже хочу на море\n",
    "# Мы летим в горы с кошками -> Я тоже лечу в горы с кошками \n",
    "# Мы летим в горы, а потом на марс. -> зачем?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "марс"
      ]
     },
     "execution_count": 117,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# функция для нахождения подлежащего в тексте. к которому будет относится наш предлог\n",
    "\n",
    "def find_noun(sents):\n",
    "    \"\"\"\n",
    "    sents - предложения;\n",
    "    Будем использовать эту функцию для находление нужного подлежащего в предложении\n",
    "    в котором мы нашли нужный маттерн.\n",
    "    \"\"\"\n",
    "    for sent in reversed(sents):\n",
    "        for token in sents:\n",
    "            if token.dep_ == 'case':\n",
    "                return token.head\n",
    "\n",
    "    return 'Noun not found'\n",
    "\n",
    "# Мы хотим на марс.\n",
    "find_noun(doc) # вау. всё правильно!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Я тоже на марс'"
      ]
     },
     "execution_count": 118,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Теперь генерируем наше ответное высказывание, которое соответсвует нашему паттерну.\n",
    "def gen_answer(doc, noun):\n",
    "    sent = ''\n",
    "    for i,token in enumerate(doc):\n",
    "        if token.dep_ == 'ROOT':\n",
    "            sent = \"Я тоже \" + doc[i+1:].text\n",
    "            return sent\n",
    "\n",
    "gen_answer(doc,\"s\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "марс 10 14 LOC\n",
      "Питербург 95 104 LOC\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<span class=\"tex2jax_ignore\"><div class=\"entities\" style=\"line-height: 2.5; direction: ltr\">Я хочу на \n",
       "<mark class=\"entity\" style=\"background: #ff9561; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    марс\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">LOC</span>\n",
       "</mark>\n",
       " купить там вкусных булочек. А потом послушать красивую музыку и улететь домой в \n",
       "<mark class=\"entity\" style=\"background: #ff9561; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    Питербург\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">LOC</span>\n",
       "</mark>\n",
       "</div></span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "doc = nlp(\"Я хочу на марс купить там вкусных булочек. А потом послушать красивую музыку и улететь домой в Питербург\")\n",
    "for ent in doc.ents:\n",
    "    print(ent.text,ent.start_char, ent.end_char, ent.label_)  \n",
    "displacy.render(doc, style = 'ent')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.0 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "6ce3869865918335a5f7f8bf564fd081cbfe04ed0827b527a250169e23ceeace"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
