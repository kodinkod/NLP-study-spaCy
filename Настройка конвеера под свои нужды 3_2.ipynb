{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Настройка компонентов конвейера под свои нужды"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Что если конвеер распознает что-то не так как нам нужно. Допустим как страну, а не название компаниии."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy as sp\n",
    "nlp = sp.load('ru_core_news_sm')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Москву LOC\n"
     ]
    }
   ],
   "source": [
    "doc = nlp(u'Я хочу купить Москву')\n",
    "for ent in doc.ents:\n",
    "    print(ent.text, ent.label_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "А у нас допустим Москва это название конфет"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Компонент для распознавания сущностей реализован в API библиотеки spaCy в виде класса EntityRecognizer.С помощью методов этого\n",
    "класса можно инициализировать экземпляр ner и применить его\n",
    "к тексту. В большинстве случаев описывать операции явным образом\n",
    "не нужно: spaCy делает это автоматически при создании объекта nlp,\n",
    "а затем и объекта Doc соответственно."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "# но придётся явным образом работать собъектом ner.\n",
    "# Сначала добавим новую метку  - \"название конфет\" SWEET\n",
    "# Затем подадим обучающийся набор данных, чтобы модель поняла, что такое \"название конфет\" SWEET\n",
    "\n",
    "LABEL = 'SWEET'\n",
    "\n",
    "# тренировочные данные. \n",
    "# (17, 23.. - место где стоит та самая метка которую мы вводим\n",
    "TRAIN_DATA = [\n",
    "    ('Нам нужно купить Москву', {'entities': [(17, 23, 'SWEET')]}), \n",
    "    ('Я хочу пить', {'entities': []}) # здесь нет элемента этого. Это важно для обучения\n",
    "]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# получаем экземпляр конвеера ner\n",
    "ner = nlp.get_pipe('ner')\n",
    "\n",
    "# добавим метку \n",
    "ner.add_label(LABEL)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Прежде чем приступить к обучению средства распознавания сущностей, необходимо отключить остальные конвейеры, чтобы во время\n",
    "обучения обновлялся только компонент распознавания сущностей:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['tok2vec', 'morphologizer', 'parser', 'attribute_ruler', 'lemmatizer', 'ner']\n"
     ]
    }
   ],
   "source": [
    "meta_on = nlp.meta['pipeline'] #список компонентов конвейера, используемых с моделью\n",
    "print(meta_on)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "# отключаем компоненты \n",
    "for component in meta_on:\n",
    "    if component != 'ner':\n",
    "        nlp.disable_pipes(component)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Примеры данных во время обучения демонстрируютсямодели в цикле\n",
    "в случайномпорядке, чтобы какможно эффективнее обновлять данные\n",
    "модели и избегать каких-либо обобщающих выводов из очередности\n",
    "обучающих примеров. Выполнение этого кода займет некоторое время"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "# теперь можно начать обучение\n",
    "\n",
    "from spacy.training.example import Example\n",
    "\n",
    "for i in range(25):\n",
    "    random.shuffle(TRAIN_DATA)\n",
    "    for batch in sp.util.minibatch(TRAIN_DATA, size=2):\n",
    "        for text, annotations in batch:\n",
    "            # create Example\n",
    "            doc = nlp.make_doc(text)\n",
    "            example = Example.from_dict(doc, annotations)\n",
    "            # Update the model\n",
    "            nlp.update([example])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Москву SWEET\n",
      "Москва SWEET\n"
     ]
    }
   ],
   "source": [
    "\n",
    "doc = nlp(u'Хочу скушать Москву')\n",
    "for ent in doc.ents:\n",
    "    print(ent.text, ent.label_)\n",
    "\n",
    "doc = nlp(u'Ехать в Москва')\n",
    "for ent in doc.ents:\n",
    "    print(ent.text, ent.label_)\n",
    "\n",
    "# теперь москва это не локация а конфеты\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Учтите: внесенные только что обновления будут утрачены сразу после\n",
    "закрытия текущего сеанса интерпретатора Python. Для решения этой\n",
    "проблемы в классе Pipe, родительском для класса EntityRecognizer\n",
    "и других классов компонентов конвейера, предусмотрен метод to_\n",
    "disk(), предназначенный для сериализации конвейера на диск:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#ner.to_disk('/usr/to/ner')\n",
    "'''\n",
    "\n",
    "загрузка\n",
    "import spacy\n",
    "from spacy.pipeline import EntityRecognizer\n",
    "nlp = spacy.load('en', disable=['ner'])\n",
    "\n",
    "ner = EntityRecognizer(nlp.vocab)\n",
    "ner.from_disk('/usr/to/ner')\n",
    "nlp.add_pipe(ner)\n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Вы загрузили модель, отключив ее компонент ner по умолчанию .\n",
    "Затем создали новый экземпляр ner , после чего загрузили данные\n",
    "с диска . Добавили компонент ner в конвейер обработки ."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.0 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "6ce3869865918335a5f7f8bf564fd081cbfe04ed0827b527a250169e23ceeace"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
