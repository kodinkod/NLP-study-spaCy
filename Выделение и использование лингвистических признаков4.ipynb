{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Выделение и использование лингвистических признаков\n",
    "==============\n",
    "20.10.2022"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Выделение и генерация текста с помощью тегов частей речи"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy as sp\n",
    "nlp = sp.load('ru_core_news_lg')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Теги для чисел, символов и знаков препинания"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Привет NOUN noun\n",
      ", PUNCT punctuation\n",
      "вы PRON pronoun\n",
      "должны ADJ adjective\n",
      "мне PRON pronoun\n",
      "$ SYM symbol\n",
      "12 NUM numeral\n",
      "тысяч NOUN noun\n",
      ". PUNCT punctuation\n"
     ]
    }
   ],
   "source": [
    "doc = nlp(u\"Привет, вы должны мне $12 тысяч. \")\n",
    "for token in doc:\n",
    "    print(token.text, token.pos_,sp.explain(token.pos_))\n",
    "\n",
    "# explain(token.pos_) возвращает описание токена"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Второй и третий столбцы содержат теги общих и уточненных частей речи соответственно. В четвертом столбце приведено описание тегов уточненных частей речи из третьего столбца."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Вы PRON PRON\n",
      "должны ADJ ADJ\n",
      "мне PRON PRON\n",
      "$ SYM SYM\n",
      "12 NUM NUM\n",
      "миллионов NOUN NOUN\n",
      ". PUNCT PUNCT\n"
     ]
    }
   ],
   "source": [
    "doc = nlp(u\"Вы должны мне $12 миллионов. \")\n",
    "for token in doc:\n",
    "    print(token.text, token.pos_, token.tag_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Почему pos_ и tag_ совпадают в русском языке????????????????????????????????/s\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The DET DT\n",
      "firm NOUN NN\n",
      "earned VERB VBD\n",
      "$ SYM $\n",
      "1.5 NUM CD\n",
      "million NUM CD\n",
      "in ADP IN\n",
      "2017 NUM CD\n",
      ". PUNCT .\n"
     ]
    }
   ],
   "source": [
    "nlp_en = sp.load('en_core_web_sm')\n",
    "doc_en = nlp_en(u'The firm earned $1.5 million in 2017.')\n",
    "\n",
    "for token in doc_en:\n",
    "    print(token.text, token.pos_, token.tag_)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Преобразование утвердительных высказываний\n",
    "##### в вопросительные\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Допустим, наше NLP-приложение должно генерировать вопросы на\n",
    "основе полученных утвердительных высказываний."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Я PRON PRON nsubj умею nominal subject\n",
      "умею VERB VERB ROOT умею root\n",
      "водить VERB VERB xcomp умею open clausal complement\n",
      "машину NOUN NOUN obj водить object\n",
      ". PUNCT PUNCT punct умею punctuation\n"
     ]
    }
   ],
   "source": [
    "doc = nlp(u\"Я умею водить машину.\")\n",
    "for token in doc:\n",
    "    print(token.text, token.pos_, token.tag_, token.dep_, token.head.text, sp.explain(token.dep_))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Вы умею водить машину ?'"
      ]
     },
     "execution_count": 115,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sent=''\n",
    "for i, token in enumerate(doc):\n",
    "    if token.pos_ == \"PRON\":\n",
    "        sent+='Вы '\n",
    "    elif token.text == \".\":\n",
    "        sent+='?'\n",
    "    else:\n",
    "        sent+=token.text + ' '\n",
    "\n",
    "\n",
    "sent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Я PRON PRON nsubj хочу nominal subject\n",
      "хочу VERB VERB ROOT хочу root\n",
      "красную ADJ ADJ amod грушу adjectival modifier\n",
      "грушу NOUN NOUN obj хочу object\n",
      ". PUNCT PUNCT punct хочу punctuation\n"
     ]
    }
   ],
   "source": [
    "doc = nlp(u\"Я хочу красную грушу.\")\n",
    "for token in doc:\n",
    "    print(token.text, token.pos_, token.tag_, token.dep_, token.head.text, sp.explain(token.dep_))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_chunk(doc):\n",
    "    chunk = ''\n",
    "    for i,token in enumerate(doc):\n",
    "        if token.dep_ == 'obj':\n",
    "            shift = len([w for w in  token.children])\n",
    "            chunk = doc[i-shift:i+2]\n",
    "            break\n",
    "    return chunk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "красную грушу."
      ]
     },
     "execution_count": 142,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "s=find_chunk(doc)\n",
    "s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [],
   "source": [
    "def determine_question_type(chunk):\n",
    "    question_type = 'yesno'\n",
    "    for token in chunk:\n",
    "        if token.dep_ == 'amod':\n",
    "            question_type = 'info'\n",
    "    return question_type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [],
   "source": [
    "type = determine_question_type(s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_question(doc, question_type):\n",
    "    sent = ''\n",
    "    for i, token in enumerate(doc):\n",
    "        if token.pos_ == \"PRON\":\n",
    "            sent+='Вы '\n",
    "        elif token.text == \".\":\n",
    "            sent+='?'\n",
    "        else:\n",
    "            sent+=token.text + ' '\n",
    "\n",
    "    doc=nlp(sent)\n",
    "    if question_type == 'info':\n",
    "        for i,token in enumerate(doc):\n",
    "            if token.dep_ == 'obj':\n",
    "                shift = len([w for w in  token.children])\n",
    "                chunk = doc[i-shift:i+2]\n",
    "                sent = 'Зачем вам ' + chunk.text \n",
    "                break\n",
    "    if question_type == 'yesno':\n",
    "        for i,token in enumerate(doc):\n",
    "            if token.dep_ == 'dobj':\n",
    "                sent = doc[:i-1].text + ' a red ' + doc[i:].text\n",
    "                break\n",
    "    doc=nlp(sent)\n",
    "\n",
    "\n",
    "    return sent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "info\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'Вы хочу домой ?'"
      ]
     },
     "execution_count": 176,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "\n",
    "doc = nlp(u\"Я хочу домой.\")\n",
    "type = determine_question_type(s)\n",
    "print(type)\n",
    "generate_question(doc, type)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.0 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "6ce3869865918335a5f7f8bf564fd081cbfe04ed0827b527a250169e23ceeace"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
