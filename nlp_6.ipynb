{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 6. Поиск паттернов и обход деревьев зависимостей\n",
    "\n",
    "стр 116\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "В этой главе рассматриваются еще два подхода: использование паттернов (закономерностей) последовательностей слов для классификации и генерации текста, а также выделение из высказывания необходимых элементов информации путем обхода его дерева синтаксических зависимостей. Вы познакомитесь с утилитой Matcher библиотеки spaCy, предназначенной для поиска закономерностей. А также узнаете, в каких случаях для определения нужного подхода к обработке все равно приходится учитывать контекст."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Бвают совершенно различные предложения, но с одинаковыми паттернами (частями речи и зависимости между нимим)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy as sp\n",
    "nlp = sp.load('ru_core_news_lg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "doc1 = nlp(\"Я хочу на море\")\n",
    "doc2 = nlp(\"Мы летим в горы\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Я Мы nsubj nsubj\n",
      "хочу летим ROOT ROOT\n",
      "на в case case\n",
      "море горы obl obl\n"
     ]
    }
   ],
   "source": [
    "for i in range(len(doc1)):\n",
    "    print(doc1[i].text, doc2[i].text, doc1[i].dep_,doc2[i].dep_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Видно, что предложения совсем рахные, но паттерн у них одинкаовый: nsubj+ROOT+case+obl\n",
    "\n",
    "подробней об dep_ можно прочитать в start.ipynb // если коротко, то это метка синтакчической зависимости. Например, ROOT -означает, что это слово-смысловой глагол"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "поиск паттернов лучше. Потому что могут быть различные предложения по содержанию и смыслу, но одинаковые по построению"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Я nsubj\n",
      "хочу ROOT\n",
      "на case\n",
      "море obl\n",
      ". punct\n",
      "----------\n",
      "Мы nsubj\n",
      "летим ROOT\n",
      "в case\n",
      "горы obl\n",
      ". punct\n",
      "----------\n"
     ]
    }
   ],
   "source": [
    "# ПОПРОБУЙТЕ САМИ стр 118\n",
    "doc = nlp(\"Я хочу на море.Мы летим в горы.\")\n",
    "for item in doc.sents:\n",
    "    sentence = list(item)\n",
    "    for word in sentence:\n",
    "        print(word.text,word.dep_)\n",
    "    print(5*\"--\")\n",
    "\n",
    "# эффективней создавать один контейнер doc и приминять один раз nlp. Чем создавать два контейнера и проходить по ним. \n",
    "# Используй doc.sents "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Проверка высказывания на соответствие паттерну"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "На практике же обычно нет смысла сравнивать предложения друг с другом для выяснения, объединяет ли их один паттерн. Вместо этого стоит проверить полученное предложение на соответствие нужному нам паттерну."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------\n",
      "TEXT Я nsubj\n",
      "HEAD хочу nsubj\n",
      "<children\n",
      "/children>\n",
      "----------\n",
      "----------\n",
      "TEXT хочу ROOT\n",
      "HEAD хочу ROOT\n",
      "<children\n",
      "Я nsubj\n",
      "море obl\n",
      ". punct\n",
      "/children>\n",
      "----------\n",
      "----------\n",
      "TEXT на case\n",
      "HEAD море case\n",
      "<children\n",
      "/children>\n",
      "----------\n",
      "----------\n",
      "TEXT море obl\n",
      "HEAD хочу obl\n",
      "<children\n",
      "на case\n",
      "/children>\n",
      "----------\n",
      "----------\n",
      "TEXT . punct\n",
      "HEAD хочу punct\n",
      "<children\n",
      "/children>\n",
      "----------\n"
     ]
    }
   ],
   "source": [
    "# попробуем увидеть, как паттерн можно отследить \n",
    "# nsubj+ROOT+case+obl\n",
    "doc = nlp(\"Я хочу на море.\")\n",
    "\n",
    "for item in doc:\n",
    "    print(5*'--')\n",
    "    print('TEXT', item.text, item.dep_)\n",
    "    print('HEAD', item.head, item.dep_)\n",
    "    print(\"<children\")\n",
    "    for g in item.children:\n",
    "        print(g, g.dep_)\n",
    "    print('/children>')\n",
    "    print(5*'--')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dep_pattern(doc):\n",
    "    # если паттерн есть в предложении, то вернем true \n",
    "    for i in range(len(doc)-1):\n",
    "        if doc[i].dep_ == \"nsubj\":\n",
    "            #print(doc[i])\n",
    "            if doc[i].head.dep_ == \"ROOT\":\n",
    "            #    print(doc[i].head)\n",
    "                for child in doc[i].head.children:\n",
    "                    if child.dep_ ==\"obl\":\n",
    "                        return True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Я хочу на море\n",
      "found\n",
      "Мы летим в горы\n",
      "found\n",
      "Я купил машину\n",
      "dint found\n",
      "Мы летим в горы, а потом на море\n",
      "found\n"
     ]
    }
   ],
   "source": [
    "doc1 = nlp(\"Я хочу на море\")\n",
    "doc2 = nlp(\"Мы летим в горы\")\n",
    "doc3 = nlp(\"Я купил машину\")\n",
    "doc4 = nlp(\"Мы летим в горы, а потом на море\")\n",
    "\n",
    "testing = [doc1, doc2, doc3, doc4]\n",
    "\n",
    "\n",
    "for test in testing:\n",
    "    print(test.text)\n",
    "    if dep_pattern(test):\n",
    "        print(\"found\")\n",
    "    else:\n",
    "        print(\"dint found\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Использование утилиты Matcher библиотеки spaCy для поиска паттернов последовательностей слов"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![alt text](matcher.jpeg \"matcher\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "from spacy.matcher import Matcher"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SPAN: Я хочу на море\n",
      "Позиция в доке:  0 - 4\n"
     ]
    }
   ],
   "source": [
    "# DEP обращаемся по токену \n",
    "# nsubj+ROOT+case+obl\n",
    "\n",
    "matcher = Matcher(nlp.vocab)\n",
    "pattern = [{\"DEP\":\"nsubj\"},{\"DEP\":\"ROOT\"},{\"DEP\":\"case\"},{\"DEP\":\"obl\"}]\n",
    "matcher.add(\"NsubjRootcaseobl\", [pattern])\n",
    "\n",
    "doc = nlp(\"Я хочу на море. а он не хочет.\")\n",
    "\n",
    "match = matcher(doc)\n",
    "for match_id, start, end in match:\n",
    "    span = doc[start:end]\n",
    "    print(\"SPAN:\", span.text)\n",
    "    print('Позиция в доке: ',start,'-',end)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Матчер позволяет искать паттерны только, когда слова идут друг за другом. Если паттерн у нас такой: nsubj+ROOT+..<какой то текст>..+case+obl ; то матчер у нас не сможет работать. Далее посмотрим, как ещё можно искать паттерны в тексте."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Применение нескольких паттернов"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Одно высказывание можно сопоставить с несколькими паттернами, дабы убедиться, что оно удовлетворяет всем нужным условиям. Например, с двумя паттернами: с реализующим последовательность меток зависимости (как обсуждалось в подразделе «Проверка высказывания на соответствие паттерну» на с. 119) и с проверяющим на соответствие последовательности тегов частей речи. Это может пригодиться, скажем, если будет нужно убедиться, что в роли прямого дополнения в высказывании выступает личное местоимение. В таком случае можно начать поиск соответствующего этому местоимению существительного, упомянутого где-то в другом месте текста."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Напоминим - \n",
    "dep - это то, чем является слово в предложении по отношению к другим словам.\n",
    "\n",
    "pos - это часть речи. (PRON, VERB)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Я nsubj PRON\n",
      "хочу ROOT VERB\n",
      "на case ADP\n",
      "море obl NOUN\n",
      ". punct PUNCT\n",
      "----------\n",
      "Мы nsubj PRON\n",
      "летим ROOT VERB\n",
      "в case ADP\n",
      "горы obl NOUN\n",
      ". punct PUNCT\n",
      "----------\n"
     ]
    }
   ],
   "source": [
    "#увидим, что dep паттерн может совпасть, а pos паттерн совсем другой. Тогда нам нужна дополнительная функция \n",
    "#которая бы отбирала нужные части речи.\n",
    "\n",
    "doc = nlp(\"Я хочу на море.Мы летим в горы.\")\n",
    "for item in doc.sents:\n",
    "    sentence = list(item)\n",
    "    for word in sentence:\n",
    "        print(word.text,word.dep_, word.tag_)\n",
    "    print(5*\"--\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found\n"
     ]
    }
   ],
   "source": [
    "\n",
    "doc = nlp(\"Я хочу на море. а он не хочет.\")\n",
    "\n",
    "# ИЩЕМ: nsubj+ROOT+case+obl\n",
    "#       PRON +VERB+ --+---\n",
    "\n",
    "# уже было\n",
    "def dep_pattern(doc):\n",
    "    # если паттерн есть в предложении, то вернем true \n",
    "    for i in range(len(doc)-1):\n",
    "        if doc[i].dep_ == \"nsubj\":\n",
    "            #print(doc[i])\n",
    "            if doc[i].head.dep_ == \"ROOT\":\n",
    "            #    print(doc[i].head)\n",
    "                for child in doc[i].head.children:\n",
    "                    if child.dep_ ==\"obl\":\n",
    "                        return True\n",
    "\n",
    "#дополняем \\\\ Можно точечно указать части речи, которые нас интересуют  \n",
    "def pos_pattern(doc):\n",
    "    for token in doc:\n",
    "        if token.dep_ == 'nsubj' and token.tag_ != 'PRON':\n",
    "            return False\n",
    "        if token.dep_ == 'ROOT' and token.tag_ != 'VERB':\n",
    "            return False\n",
    "    return True\n",
    "    \n",
    "# тестируем\n",
    "if dep_pattern(doc) and pos_pattern(doc):\n",
    "    print('Found')\n",
    "else:\n",
    "    print('Not found')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Создание паттернов на основе пользовательских признаков"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "При создании паттерна последовательности слов может возникнуть необходимость расширить функциональность лингвистических признаков, предоставляемых spaCy, подогнав их под свои задачи. Например, может понадобиться, чтобы предыдущий сценарий распознавал паттерн, в котором учитывается число местоимений (единственное или множественное). Это полезно в том случае, если нужно найти существительное, к которому относится местоимение."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Допустим нужно изучить существительное. Тогда нам нужно бы найти местоимение во множественном числе и найти относящееся к нему существительное."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "следующем сценарии описывается функция pron_pattern, которая находит все прямые дополнения в передаваемом ей предложении, определяет, является ли прямое дополнение личным местоимением, а затем выясняет, в каком оно числе: единственном или множественном. Далее функция применяется к примеру предложения после проверки его на соответствие двум паттернам, описанным в подразделах «Проверка высказывания на соответствие паттерну» на с. 119 и «Применение нескольких паттернов» на с. 122."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------------------------------\n",
      "Мы хотим на марс.\n",
      "Found: the pronoun in position of direct object is plural\n",
      "------------------------------------------------------------\n",
      "Я хочу марс.\n",
      "Not found\n",
      "------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "# исспользуем наши dep_pattern и pos_pattern\n",
    "\n",
    "def pron_pattern(doc):\n",
    "    plural = ['Мы','нам','они','им']\n",
    "    for token in doc:\n",
    "        if token.dep_ == 'nsubj' and token.tag_ == 'PRON':   # обнаруживаем местоимение в паттерне играющее роль nsubj\n",
    "            if token.text in plural:                        # если это местоимение в множественном числе \n",
    "                return 'plural'\n",
    "            else:\n",
    "                return 'singular'\n",
    "    return 'not found'\n",
    "\n",
    "\n",
    "\n",
    "print(30*\"--\")\n",
    "doc = nlp(u'Мы хотим на марс.')\n",
    "print(doc.text)\n",
    "if dep_pattern(doc) and pos_pattern(doc):\n",
    "    print('Found:', 'the pronoun in position of direct object is',\n",
    "    pron_pattern(doc))\n",
    "else:\n",
    "    print('Not found')\n",
    "\n",
    "print(30*\"--\")\n",
    "doc = nlp(u'Я хочу марс.')\n",
    "print(doc.text)\n",
    "if dep_pattern(doc) and pos_pattern(doc):\n",
    "    print('Found:', 'the pronoun in position of direct object is',\n",
    "    pron_pattern(doc))\n",
    "else:\n",
    "    print('Not found')\n",
    "\n",
    "print(30*\"--\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.0 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "6ce3869865918335a5f7f8bf564fd081cbfe04ed0827b527a250169e23ceeace"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
